{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "33d0d72b-19f9-486f-a150-b4a8d1979edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, LabelEncoder, FunctionTransformer, OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from imblearn.over_sampling import SMOTE, RandomOverSampler, BorderlineSMOTE, ADASYN\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7864a250-8f35-45a4-aaa2-a9175d7a214f",
   "metadata": {},
   "source": [
    "### Experiments to find best sampling techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c80e997c-94ee-4516-abd3-ea84c3d8002e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sampling Technique: None\n",
      "\n",
      "Model: Dummy\n",
      "Accuracy: 0.6954\n",
      "Precision: 1.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      1.00      0.82     86319\n",
      "           1       1.00      0.00      0.00     37812\n",
      "\n",
      "    accuracy                           0.70    124131\n",
      "   macro avg       0.85      0.50      0.41    124131\n",
      "weighted avg       0.79      0.70      0.57    124131\n",
      "\n",
      "\n",
      "Model: DecisionTree\n",
      "Accuracy: 0.5967\n",
      "Precision: 0.3252\n",
      "Recall: 0.3014\n",
      "F1 Score: 0.3129\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.73      0.71     86319\n",
      "           1       0.33      0.30      0.31     37812\n",
      "\n",
      "    accuracy                           0.60    124131\n",
      "   macro avg       0.51      0.51      0.51    124131\n",
      "weighted avg       0.59      0.60      0.59    124131\n",
      "\n",
      "\n",
      "Model: RandomForest\n",
      "Accuracy: 0.6186\n",
      "Precision: 0.3323\n",
      "Recall: 0.2498\n",
      "F1 Score: 0.2852\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.78      0.74     86319\n",
      "           1       0.33      0.25      0.29     37812\n",
      "\n",
      "    accuracy                           0.62    124131\n",
      "   macro avg       0.52      0.51      0.51    124131\n",
      "weighted avg       0.59      0.62      0.60    124131\n",
      "\n",
      "\n",
      "Model: LogisticRegression\n",
      "Accuracy: 0.6954\n",
      "Precision: 1.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      1.00      0.82     86319\n",
      "           1       1.00      0.00      0.00     37812\n",
      "\n",
      "    accuracy                           0.70    124131\n",
      "   macro avg       0.85      0.50      0.41    124131\n",
      "weighted avg       0.79      0.70      0.57    124131\n",
      "\n",
      "[LightGBM] [Info] Number of positive: 88013, number of negative: 201624\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006549 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 134\n",
      "[LightGBM] [Info] Number of data points in the train set: 289637, number of used features: 34\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.303873 -> initscore=-0.828920\n",
      "[LightGBM] [Info] Start training from score -0.828920\n",
      "\n",
      "Model: LightGBM\n",
      "Accuracy: 0.6954\n",
      "Precision: 0.5000\n",
      "Recall: 0.0001\n",
      "F1 Score: 0.0002\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      1.00      0.82     86319\n",
      "           1       0.50      0.00      0.00     37812\n",
      "\n",
      "    accuracy                           0.70    124131\n",
      "   macro avg       0.60      0.50      0.41    124131\n",
      "weighted avg       0.64      0.70      0.57    124131\n",
      "\n",
      "\n",
      "Model: NeuralNetwork\n",
      "Accuracy: 0.6953\n",
      "Precision: 0.3043\n",
      "Recall: 0.0002\n",
      "F1 Score: 0.0004\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      1.00      0.82     86319\n",
      "           1       0.30      0.00      0.00     37812\n",
      "\n",
      "    accuracy                           0.70    124131\n",
      "   macro avg       0.50      0.50      0.41    124131\n",
      "weighted avg       0.58      0.70      0.57    124131\n",
      "\n",
      "\n",
      "Sampling Technique: RandomOverSampler\n",
      "\n",
      "Model: Dummy\n",
      "Accuracy: 0.6954\n",
      "Precision: 1.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      1.00      0.82     86319\n",
      "           1       1.00      0.00      0.00     37812\n",
      "\n",
      "    accuracy                           0.70    124131\n",
      "   macro avg       0.85      0.50      0.41    124131\n",
      "weighted avg       0.79      0.70      0.57    124131\n",
      "\n",
      "\n",
      "Model: DecisionTree\n",
      "Accuracy: 0.5789\n",
      "Precision: 0.3230\n",
      "Recall: 0.3489\n",
      "F1 Score: 0.3354\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.68      0.69     86319\n",
      "           1       0.32      0.35      0.34     37812\n",
      "\n",
      "    accuracy                           0.58    124131\n",
      "   macro avg       0.51      0.51      0.51    124131\n",
      "weighted avg       0.59      0.58      0.58    124131\n",
      "\n",
      "\n",
      "Model: RandomForest\n",
      "Accuracy: 0.5877\n",
      "Precision: 0.3277\n",
      "Recall: 0.3362\n",
      "F1 Score: 0.3319\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.70      0.70     86319\n",
      "           1       0.33      0.34      0.33     37812\n",
      "\n",
      "    accuracy                           0.59    124131\n",
      "   macro avg       0.52      0.52      0.52    124131\n",
      "weighted avg       0.59      0.59      0.59    124131\n",
      "\n",
      "\n",
      "Model: LogisticRegression\n",
      "Accuracy: 0.6168\n",
      "Precision: 0.3898\n",
      "Recall: 0.4562\n",
      "F1 Score: 0.4204\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.69      0.71     86319\n",
      "           1       0.39      0.46      0.42     37812\n",
      "\n",
      "    accuracy                           0.62    124131\n",
      "   macro avg       0.57      0.57      0.57    124131\n",
      "weighted avg       0.64      0.62      0.62    124131\n",
      "\n",
      "[LightGBM] [Info] Number of positive: 201624, number of negative: 201624\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008796 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 134\n",
      "[LightGBM] [Info] Number of data points in the train set: 403248, number of used features: 34\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "\n",
      "Model: LightGBM\n",
      "Accuracy: 0.5860\n",
      "Precision: 0.3740\n",
      "Recall: 0.5332\n",
      "F1 Score: 0.4396\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.61      0.67     86319\n",
      "           1       0.37      0.53      0.44     37812\n",
      "\n",
      "    accuracy                           0.59    124131\n",
      "   macro avg       0.56      0.57      0.56    124131\n",
      "weighted avg       0.63      0.59      0.60    124131\n",
      "\n",
      "\n",
      "Model: NeuralNetwork\n",
      "Accuracy: 0.5610\n",
      "Precision: 0.3621\n",
      "Recall: 0.5793\n",
      "F1 Score: 0.4456\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.55      0.64     86319\n",
      "           1       0.36      0.58      0.45     37812\n",
      "\n",
      "    accuracy                           0.56    124131\n",
      "   macro avg       0.56      0.57      0.54    124131\n",
      "weighted avg       0.63      0.56      0.58    124131\n",
      "\n",
      "\n",
      "Sampling Technique: RandomUnderSampler\n",
      "\n",
      "Model: Dummy\n",
      "Accuracy: 0.6954\n",
      "Precision: 1.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      1.00      0.82     86319\n",
      "           1       1.00      0.00      0.00     37812\n",
      "\n",
      "    accuracy                           0.70    124131\n",
      "   macro avg       0.85      0.50      0.41    124131\n",
      "weighted avg       0.79      0.70      0.57    124131\n",
      "\n",
      "\n",
      "Model: DecisionTree\n",
      "Accuracy: 0.5261\n",
      "Precision: 0.3192\n",
      "Recall: 0.4904\n",
      "F1 Score: 0.3867\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.54      0.61     86319\n",
      "           1       0.32      0.49      0.39     37812\n",
      "\n",
      "    accuracy                           0.53    124131\n",
      "   macro avg       0.51      0.52      0.50    124131\n",
      "weighted avg       0.59      0.53      0.54    124131\n",
      "\n",
      "\n",
      "Model: RandomForest\n",
      "Accuracy: 0.5266\n",
      "Precision: 0.3274\n",
      "Recall: 0.5254\n",
      "F1 Score: 0.4034\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.53      0.61     86319\n",
      "           1       0.33      0.53      0.40     37812\n",
      "\n",
      "    accuracy                           0.53    124131\n",
      "   macro avg       0.52      0.53      0.51    124131\n",
      "weighted avg       0.60      0.53      0.55    124131\n",
      "\n",
      "\n",
      "Model: LogisticRegression\n",
      "Accuracy: 0.6168\n",
      "Precision: 0.3898\n",
      "Recall: 0.4562\n",
      "F1 Score: 0.4204\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.69      0.71     86319\n",
      "           1       0.39      0.46      0.42     37812\n",
      "\n",
      "    accuracy                           0.62    124131\n",
      "   macro avg       0.57      0.57      0.57    124131\n",
      "weighted avg       0.64      0.62      0.62    124131\n",
      "\n",
      "[LightGBM] [Info] Number of positive: 88013, number of negative: 88013\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005225 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 134\n",
      "[LightGBM] [Info] Number of data points in the train set: 176026, number of used features: 34\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "\n",
      "Model: LightGBM\n",
      "Accuracy: 0.5802\n",
      "Precision: 0.3708\n",
      "Recall: 0.5426\n",
      "F1 Score: 0.4405\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.60      0.66     86319\n",
      "           1       0.37      0.54      0.44     37812\n",
      "\n",
      "    accuracy                           0.58    124131\n",
      "   macro avg       0.56      0.57      0.55    124131\n",
      "weighted avg       0.63      0.58      0.60    124131\n",
      "\n",
      "\n",
      "Model: NeuralNetwork\n",
      "Accuracy: 0.6143\n",
      "Precision: 0.3880\n",
      "Recall: 0.4611\n",
      "F1 Score: 0.4214\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.68      0.71     86319\n",
      "           1       0.39      0.46      0.42     37812\n",
      "\n",
      "    accuracy                           0.61    124131\n",
      "   macro avg       0.57      0.57      0.57    124131\n",
      "weighted avg       0.63      0.61      0.62    124131\n",
      "\n",
      "\n",
      "Sampling Technique: SMOTE\n",
      "\n",
      "Model: Dummy\n",
      "Accuracy: 0.6954\n",
      "Precision: 1.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      1.00      0.82     86319\n",
      "           1       1.00      0.00      0.00     37812\n",
      "\n",
      "    accuracy                           0.70    124131\n",
      "   macro avg       0.85      0.50      0.41    124131\n",
      "weighted avg       0.79      0.70      0.57    124131\n",
      "\n",
      "\n",
      "Model: DecisionTree\n",
      "Accuracy: 0.5904\n",
      "Precision: 0.3240\n",
      "Recall: 0.3174\n",
      "F1 Score: 0.3207\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.71      0.71     86319\n",
      "           1       0.32      0.32      0.32     37812\n",
      "\n",
      "    accuracy                           0.59    124131\n",
      "   macro avg       0.51      0.51      0.51    124131\n",
      "weighted avg       0.59      0.59      0.59    124131\n",
      "\n",
      "\n",
      "Model: RandomForest\n",
      "Accuracy: 0.5976\n",
      "Precision: 0.3322\n",
      "Recall: 0.3177\n",
      "F1 Score: 0.3248\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.72      0.71     86319\n",
      "           1       0.33      0.32      0.32     37812\n",
      "\n",
      "    accuracy                           0.60    124131\n",
      "   macro avg       0.52      0.52      0.52    124131\n",
      "weighted avg       0.59      0.60      0.60    124131\n",
      "\n",
      "\n",
      "Model: LogisticRegression\n",
      "Accuracy: 0.6166\n",
      "Precision: 0.3897\n",
      "Recall: 0.4565\n",
      "F1 Score: 0.4205\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.69      0.71     86319\n",
      "           1       0.39      0.46      0.42     37812\n",
      "\n",
      "    accuracy                           0.62    124131\n",
      "   macro avg       0.57      0.57      0.57    124131\n",
      "weighted avg       0.64      0.62      0.62    124131\n",
      "\n",
      "[LightGBM] [Info] Number of positive: 201624, number of negative: 201624\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.032741 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 8670\n",
      "[LightGBM] [Info] Number of data points in the train set: 403248, number of used features: 34\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "\n",
      "Model: LightGBM\n",
      "Accuracy: 0.6805\n",
      "Precision: 0.4006\n",
      "Recall: 0.0987\n",
      "F1 Score: 0.1584\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.94      0.80     86319\n",
      "           1       0.40      0.10      0.16     37812\n",
      "\n",
      "    accuracy                           0.68    124131\n",
      "   macro avg       0.55      0.52      0.48    124131\n",
      "weighted avg       0.61      0.68      0.61    124131\n",
      "\n",
      "\n",
      "Model: NeuralNetwork\n",
      "Accuracy: 0.5729\n",
      "Precision: 0.3587\n",
      "Recall: 0.5105\n",
      "F1 Score: 0.4213\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.60      0.66     86319\n",
      "           1       0.36      0.51      0.42     37812\n",
      "\n",
      "    accuracy                           0.57    124131\n",
      "   macro avg       0.55      0.56      0.54    124131\n",
      "weighted avg       0.62      0.57      0.59    124131\n",
      "\n",
      "\n",
      "Sampling Technique: BorderlineSMOTE\n",
      "\n",
      "Model: Dummy\n",
      "Accuracy: 0.6954\n",
      "Precision: 1.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      1.00      0.82     86319\n",
      "           1       1.00      0.00      0.00     37812\n",
      "\n",
      "    accuracy                           0.70    124131\n",
      "   macro avg       0.85      0.50      0.41    124131\n",
      "weighted avg       0.79      0.70      0.57    124131\n",
      "\n",
      "\n",
      "Model: DecisionTree\n",
      "Accuracy: 0.5915\n",
      "Precision: 0.3250\n",
      "Recall: 0.3164\n",
      "F1 Score: 0.3206\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.71      0.71     86319\n",
      "           1       0.32      0.32      0.32     37812\n",
      "\n",
      "    accuracy                           0.59    124131\n",
      "   macro avg       0.51      0.51      0.51    124131\n",
      "weighted avg       0.59      0.59      0.59    124131\n",
      "\n",
      "\n",
      "Model: RandomForest\n",
      "Accuracy: 0.5949\n",
      "Precision: 0.3286\n",
      "Recall: 0.3163\n",
      "F1 Score: 0.3223\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.72      0.71     86319\n",
      "           1       0.33      0.32      0.32     37812\n",
      "\n",
      "    accuracy                           0.59    124131\n",
      "   macro avg       0.52      0.52      0.52    124131\n",
      "weighted avg       0.59      0.59      0.59    124131\n",
      "\n",
      "\n",
      "Model: LogisticRegression\n",
      "Accuracy: 0.6072\n",
      "Precision: 0.3840\n",
      "Recall: 0.4792\n",
      "F1 Score: 0.4264\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.66      0.70     86319\n",
      "           1       0.38      0.48      0.43     37812\n",
      "\n",
      "    accuracy                           0.61    124131\n",
      "   macro avg       0.56      0.57      0.56    124131\n",
      "weighted avg       0.63      0.61      0.62    124131\n",
      "\n",
      "[LightGBM] [Info] Number of positive: 201624, number of negative: 201624\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.033673 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 8670\n",
      "[LightGBM] [Info] Number of data points in the train set: 403248, number of used features: 34\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "\n",
      "Model: LightGBM\n",
      "Accuracy: 0.6818\n",
      "Precision: 0.3975\n",
      "Recall: 0.0865\n",
      "F1 Score: 0.1421\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.94      0.80     86319\n",
      "           1       0.40      0.09      0.14     37812\n",
      "\n",
      "    accuracy                           0.68    124131\n",
      "   macro avg       0.55      0.51      0.47    124131\n",
      "weighted avg       0.61      0.68      0.60    124131\n",
      "\n",
      "\n",
      "Model: NeuralNetwork\n",
      "Accuracy: 0.5599\n",
      "Precision: 0.3545\n",
      "Recall: 0.5418\n",
      "F1 Score: 0.4285\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.57      0.64     86319\n",
      "           1       0.35      0.54      0.43     37812\n",
      "\n",
      "    accuracy                           0.56    124131\n",
      "   macro avg       0.55      0.55      0.54    124131\n",
      "weighted avg       0.62      0.56      0.58    124131\n",
      "\n",
      "\n",
      "Sampling Technique: ADASYN\n",
      "\n",
      "Model: Dummy\n",
      "Accuracy: 0.3046\n",
      "Precision: 0.3046\n",
      "Recall: 1.0000\n",
      "F1 Score: 0.4670\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.00      0.00     86319\n",
      "           1       0.30      1.00      0.47     37812\n",
      "\n",
      "    accuracy                           0.30    124131\n",
      "   macro avg       0.65      0.50      0.23    124131\n",
      "weighted avg       0.79      0.30      0.14    124131\n",
      "\n",
      "\n",
      "Model: DecisionTree\n",
      "Accuracy: 0.5906\n",
      "Precision: 0.3224\n",
      "Recall: 0.3121\n",
      "F1 Score: 0.3172\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.71      0.71     86319\n",
      "           1       0.32      0.31      0.32     37812\n",
      "\n",
      "    accuracy                           0.59    124131\n",
      "   macro avg       0.51      0.51      0.51    124131\n",
      "weighted avg       0.59      0.59      0.59    124131\n",
      "\n",
      "\n",
      "Model: RandomForest\n",
      "Accuracy: 0.5921\n",
      "Precision: 0.3282\n",
      "Recall: 0.3237\n",
      "F1 Score: 0.3259\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.71      0.71     86319\n",
      "           1       0.33      0.32      0.33     37812\n",
      "\n",
      "    accuracy                           0.59    124131\n",
      "   macro avg       0.52      0.52      0.52    124131\n",
      "weighted avg       0.59      0.59      0.59    124131\n",
      "\n",
      "\n",
      "Model: LogisticRegression\n",
      "Accuracy: 0.5850\n",
      "Precision: 0.3734\n",
      "Recall: 0.5339\n",
      "F1 Score: 0.4394\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.61      0.67     86319\n",
      "           1       0.37      0.53      0.44     37812\n",
      "\n",
      "    accuracy                           0.59    124131\n",
      "   macro avg       0.56      0.57      0.56    124131\n",
      "weighted avg       0.63      0.59      0.60    124131\n",
      "\n",
      "[LightGBM] [Info] Number of positive: 209568, number of negative: 201624\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.034841 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 8670\n",
      "[LightGBM] [Info] Number of data points in the train set: 411192, number of used features: 34\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.509660 -> initscore=0.038644\n",
      "[LightGBM] [Info] Start training from score 0.038644\n",
      "\n",
      "Model: LightGBM\n",
      "Accuracy: 0.6803\n",
      "Precision: 0.3993\n",
      "Recall: 0.0982\n",
      "F1 Score: 0.1577\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.94      0.80     86319\n",
      "           1       0.40      0.10      0.16     37812\n",
      "\n",
      "    accuracy                           0.68    124131\n",
      "   macro avg       0.55      0.52      0.48    124131\n",
      "weighted avg       0.61      0.68      0.61    124131\n",
      "\n",
      "\n",
      "Model: NeuralNetwork\n",
      "Accuracy: 0.5906\n",
      "Precision: 0.3645\n",
      "Recall: 0.4627\n",
      "F1 Score: 0.4078\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.65      0.69     86319\n",
      "           1       0.36      0.46      0.41     37812\n",
      "\n",
      "    accuracy                           0.59    124131\n",
      "   macro avg       0.55      0.55      0.55    124131\n",
      "weighted avg       0.62      0.59      0.60    124131\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load your data\n",
    "df = pd.read_csv('../data/depression_data.csv')\n",
    "df = df.drop(columns=['Name'])\n",
    "\n",
    "# Log scaling for Income (creating this column before splitting features and target)\n",
    "df['Income'] = df['Income'].apply(lambda x: np.log(x + 1))\n",
    "\n",
    "# Splitting features and target\n",
    "X = df.drop(['History of Mental Illness'], axis=1)\n",
    "y = df['History of Mental Illness'].map({'Yes': 1, 'No': 0})\n",
    "\n",
    "# Columns setup\n",
    "categorical_cols = ['Marital Status', 'Education Level', 'Smoking Status', 'Physical Activity Level',\n",
    "                    'Employment Status', 'Alcohol Consumption', 'Dietary Habits', 'Sleep Patterns',\n",
    "                    'History of Substance Abuse', 'Family History of Depression', 'Chronic Medical Conditions']\n",
    "numeric_cols = ['Age', 'Number of Children']\n",
    "\n",
    "# One hot encoding without drop\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_cols),\n",
    "        ('cat', OneHotEncoder(drop=None), categorical_cols)\n",
    "    ])\n",
    "\n",
    "# Define models\n",
    "models = {\n",
    "    'Dummy': DummyClassifier(strategy='most_frequent'),\n",
    "    'DecisionTree': DecisionTreeClassifier(),\n",
    "    'RandomForest': RandomForestClassifier(),\n",
    "    'LogisticRegression': LogisticRegression(max_iter=1000),\n",
    "    'LightGBM': LGBMClassifier(),\n",
    "    'NeuralNetwork': MLPClassifier(hidden_layer_sizes=(64, 32), early_stopping=True)\n",
    "}\n",
    "\n",
    "# Sampling techniques\n",
    "sampling_methods = {\n",
    "    'None': None,\n",
    "    'RandomOverSampler': RandomOverSampler(),\n",
    "    'RandomUnderSampler': RandomUnderSampler(),\n",
    "    'SMOTE': SMOTE(),\n",
    "    'BorderlineSMOTE': BorderlineSMOTE(),\n",
    "    'ADASYN': ADASYN()\n",
    "}\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Apply preprocessing to the training data before resampling\n",
    "X_train_transformed = preprocessor.fit_transform(X_train)\n",
    "X_test_transformed = preprocessor.transform(X_test)\n",
    "\n",
    "# Iterate through each sampling method\n",
    "for sampling_name, sampler in sampling_methods.items():\n",
    "    if sampler is not None:\n",
    "        X_resampled, y_resampled = sampler.fit_resample(X_train_transformed, y_train)\n",
    "    else:\n",
    "        X_resampled, y_resampled = X_train_transformed, y_train\n",
    "\n",
    "    print(f\"\\nSampling Technique: {sampling_name}\")\n",
    "    \n",
    "    # Iterate through each model\n",
    "    for model_name, model in models.items():\n",
    "        model.fit(X_resampled, y_resampled)\n",
    "        y_pred = model.predict(X_test_transformed)\n",
    "\n",
    "        # Print metrics\n",
    "        print(f\"\\nModel: {model_name}\")\n",
    "        print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "        print(f\"Precision: {precision_score(y_test, y_pred, zero_division=1):.4f}\")\n",
    "        print(f\"Recall: {recall_score(y_test, y_pred, zero_division=1):.4f}\")\n",
    "        print(f\"F1 Score: {f1_score(y_test, y_pred, zero_division=1):.4f}\")\n",
    "        print(\"Classification Report:\")\n",
    "        print(classification_report(y_test, y_pred, zero_division=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8154178-a7e9-4a47-8c70-9c56bbbf3ba4",
   "metadata": {},
   "source": [
    "### Experiment Insights and Takeaways\n",
    "\n",
    "After conducting multiple experiments with various models and sampling techniques, here is a summary of our findings and the rationale behind our final choice:\n",
    "\n",
    "#### 1. **Sampling Techniques:**\n",
    "\n",
    "We experimented with several sampling techniques to address the class imbalance in the dataset, namely:\n",
    "- No sampling (baseline)\n",
    "- Random Over-Sampling\n",
    "- Random Under-Sampling\n",
    "- SMOTE (Synthetic Minority Over-sampling Technique)\n",
    "- BorderlineSMOTE\n",
    "- ADASYN (Adaptive Synthetic Sampling)\n",
    "\n",
    "Among these, **Random Over-Sampling** and **SMOTE** provided the best results in terms of model performance, especially when paired with Logistic Regression and Random Forest models. **SMOTE** performed slightly better than Random Over-Sampling in recall and F1 scores. Additionally, SMOTE generates synthetic samples of the minority class rather than duplicating data, which reduces the risk of overfitting.\n",
    "\n",
    "#### 2. **Model Performance Across Techniques:**\n",
    "\n",
    "- **Dummy Classifier**: \n",
    "    - As expected, the dummy classifier provided the baseline accuracy (~69%) but did not capture any of the minority class, resulting in an F1 score of 0. This highlighted the importance of balancing techniques to improve predictive power.\n",
    "\n",
    "- **Decision Tree**: \n",
    "    - The Decision Tree performed better than the dummy classifier, but its performance was still suboptimal. With **Random Over-Sampling**, it achieved an F1 score of ~0.33. However, its performance improved marginally with SMOTE to an F1 score of ~0.32. The decision tree's performance remained lower compared to other models, as it often struggles with class imbalance.\n",
    "\n",
    "- **Random Forest**: \n",
    "    - Random Forest models improved over the Decision Tree, especially with SMOTE and Random Over-Sampling. The best results were achieved with **SMOTE**, where the F1 score reached ~0.32. However, it also exhibited some limitations in handling class imbalance, especially when undersampling was used.\n",
    "\n",
    "- **Logistic Regression**: \n",
    "    - Logistic Regression consistently performed well across all sampling techniques. Its performance improved the most with **SMOTE**, reaching an F1 score of ~0.42. This model balanced simplicity with interpretability, making it a strong candidate for the final solution.\n",
    "\n",
    "- **LightGBM**: \n",
    "    - LightGBM models performed similarly across sampling methods but exhibited very low recall for the minority class. Despite a high precision, LightGBM struggled to predict the minority class (history of mental illness) effectively. Its best F1 score was observed with **SMOTE** (~0.16).\n",
    "\n",
    "- **Neural Network**: \n",
    "    - The neural network model showed promise with F1 scores of ~0.42 using SMOTE and ~0.44 with Random Over-Sampling, but it was computationally more expensive. Given that it did not outperform simpler models like Logistic Regression, it was not chosen as the final model.\n",
    "\n",
    "#### 3. **Final Model Choice: Logistic Regression + SMOTE**\n",
    "\n",
    "The Logistic Regression model with **SMOTE** consistently provided the best balance between precision, recall, and F1 scores. Here’s a quick breakdown:\n",
    "\n",
    "- **Accuracy**: ~61.68%\n",
    "- **Precision**: ~38.97%\n",
    "- **Recall**: ~45.65%\n",
    "- **F1 Score**: ~42.05%\n",
    "\n",
    "While Random Over-Sampling provided comparable results, we opted for **SMOTE** as the final sampling technique due to its ability to generate synthetic samples rather than duplicating data. This choice reduces the risk of overfitting, which can occur when oversampling simply duplicates minority class instances.\n",
    "\n",
    "#### 4. **Rationale for SMOTE Over Random Over-Sampling**\n",
    "\n",
    "Though both Random Over-Sampling and SMOTE performed similarly, SMOTE provides a more generalized and robust approach. Random Over-Sampling can lead to overfitting, as it creates exact copies of minority class instances, which can cause the model to memorize the duplicated data points rather than generalize well to unseen data. SMOTE, on the other hand, generates synthetic instances that blend the characteristics of real minority class instances, providing a more balanced and diverse representation of the minority class without overfitting.\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "For our final solution, we will move forward with **SMOTE**. This gives us a good balance between performance and simplicity, with the added benefit of reducing overfitting risks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8dc581-309b-46ff-a2e1-d8b0a958f71e",
   "metadata": {},
   "source": [
    "### Experiments to find best model and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e6647e98-f91a-446c-9d17-d773330ff24c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: DecisionTree\n",
      "--------------- Best Model: ------------------\n",
      "Pipeline(steps=[('classifier', DecisionTreeClassifier(random_state=42))])\n",
      "Best parameters found: {'classifier__max_depth': None, 'classifier__min_samples_split': 2}\n",
      "Accuracy: 0.5933\n",
      "Precision: 0.3287\n",
      "Recall: 0.3178\n",
      "F1 Score: 0.3232\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.71      0.71     57471\n",
      "           1       0.33      0.32      0.32     25283\n",
      "\n",
      "    accuracy                           0.59     82754\n",
      "   macro avg       0.52      0.52      0.52     82754\n",
      "weighted avg       0.59      0.59      0.59     82754\n",
      "\n",
      "\n",
      "Model: LogisticRegression\n",
      "--------------- Best Model: ------------------\n",
      "Pipeline(steps=[('classifier',\n",
      "                 LogisticRegression(C=0.01, random_state=42,\n",
      "                                    solver='liblinear'))])\n",
      "Best parameters found: {'classifier__C': 0.01, 'classifier__max_iter': 100, 'classifier__penalty': 'l2', 'classifier__solver': 'liblinear'}\n",
      "Accuracy: 0.6172\n",
      "Precision: 0.3919\n",
      "Recall: 0.4586\n",
      "F1 Score: 0.4226\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.69      0.71     57471\n",
      "           1       0.39      0.46      0.42     25283\n",
      "\n",
      "    accuracy                           0.62     82754\n",
      "   macro avg       0.57      0.57      0.57     82754\n",
      "weighted avg       0.64      0.62      0.62     82754\n",
      "\n",
      "\n",
      "Model: LightGBM\n",
      "[LightGBM] [Info] Number of positive: 230472, number of negative: 230472\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.030919 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 8670\n",
      "[LightGBM] [Info] Number of data points in the train set: 460944, number of used features: 34\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "--------------- Best Model: ------------------\n",
      "Pipeline(steps=[('classifier',\n",
      "                 LGBMClassifier(learning_rate=0.05, max_depth=30,\n",
      "                                n_estimators=50, random_state=42))])\n",
      "Best parameters found: {'classifier__learning_rate': 0.05, 'classifier__max_depth': 30, 'classifier__n_estimators': 50}\n",
      "Accuracy: 0.6392\n",
      "Precision: 0.4000\n",
      "Recall: 0.3621\n",
      "F1 Score: 0.3801\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.76      0.75     57471\n",
      "           1       0.40      0.36      0.38     25283\n",
      "\n",
      "    accuracy                           0.64     82754\n",
      "   macro avg       0.57      0.56      0.56     82754\n",
      "weighted avg       0.63      0.64      0.63     82754\n",
      "\n",
      "\n",
      "Model: RandomForest\n",
      "--------------- Best Model: ------------------\n",
      "Pipeline(steps=[('classifier',\n",
      "                 RandomForestClassifier(max_depth=30, min_samples_split=5,\n",
      "                                        n_estimators=150, random_state=42))])\n",
      "Best parameters found: {'classifier__max_depth': 30, 'classifier__min_samples_split': 5, 'classifier__n_estimators': 150}\n",
      "Accuracy: 0.6061\n",
      "Precision: 0.3403\n",
      "Recall: 0.3082\n",
      "F1 Score: 0.3234\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.74      0.72     57471\n",
      "           1       0.34      0.31      0.32     25283\n",
      "\n",
      "    accuracy                           0.61     82754\n",
      "   macro avg       0.52      0.52      0.52     82754\n",
      "weighted avg       0.60      0.61      0.60     82754\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "df = pd.read_csv('../data/depression_data.csv')\n",
    "df = df.drop(columns=['Name'])\n",
    "\n",
    "# Splitting features and target\n",
    "X = df.drop(['History of Mental Illness'], axis=1)\n",
    "y = df['History of Mental Illness'].map({'Yes': 1, 'No': 0})\n",
    "\n",
    "# Columns setup\n",
    "categorical_cols = ['Marital Status', 'Education Level', 'Smoking Status', 'Physical Activity Level',\n",
    "                    'Employment Status', 'Alcohol Consumption', 'Dietary Habits', 'Sleep Patterns', \n",
    "                    'History of Substance Abuse', 'Family History of Depression', 'Chronic Medical Conditions']\n",
    "numeric_cols = ['Age', 'Number of Children']\n",
    "\n",
    "# Log scaling for Income\n",
    "df['Income'] = df['Income'].apply(lambda x: np.log(x + 1))\n",
    "\n",
    "# One hot encoding and scaling\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_cols),\n",
    "        ('cat', OneHotEncoder(drop=None), categorical_cols)\n",
    "    ])\n",
    "\n",
    "# Transform the data\n",
    "X_transformed = preprocessor.fit_transform(X)\n",
    "\n",
    "# Train-test split (80-20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_transformed, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Apply SMOTE to balance the dataset\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Define models and hyperparameters for GridSearch\n",
    "model_params = {\n",
    "    'DecisionTree': {\n",
    "        'model': DecisionTreeClassifier(random_state=42),\n",
    "        'params': {\n",
    "            'classifier__max_depth': [10, 20, 30, None],\n",
    "            'classifier__min_samples_split': [2, 5, 10]\n",
    "        }\n",
    "    },\n",
    "    'LogisticRegression': {\n",
    "        'model': LogisticRegression(random_state=42),\n",
    "        'params': {\n",
    "            'classifier__max_iter': [100, 250, 500],\n",
    "            'classifier__C': [0.01, 0.1, 1, 10],\n",
    "            'classifier__penalty': ['l1', 'l2'],\n",
    "            'classifier__solver': ['liblinear', 'saga']\n",
    "        }\n",
    "    },\n",
    "    'LightGBM': {\n",
    "        'model': LGBMClassifier(random_state=42),\n",
    "        'params': {\n",
    "            'classifier__n_estimators': [50, 100, 200],\n",
    "            'classifier__max_depth': [10, 20, 30, None],\n",
    "            'classifier__learning_rate': [0.01, 0.05, 0.1]\n",
    "        }\n",
    "    },\n",
    "    'RandomForest': {\n",
    "        'model': RandomForestClassifier(random_state=42),\n",
    "        'params': {\n",
    "            'classifier__n_estimators': [50, 100, 150],\n",
    "            'classifier__max_depth': [10, 20, 30, None],\n",
    "            'classifier__min_samples_split': [2, 5, 10]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "# Iterate through each model, apply GridSearchCV and evaluate\n",
    "for model_name, mp in model_params.items():\n",
    "    print(f\"\\nModel: {model_name}\")\n",
    "    \n",
    "    # Create pipeline for model with classifier (preprocessor is already applied)\n",
    "    clf = Pipeline(steps=[('classifier', mp['model'])])\n",
    "    \n",
    "    # Perform Grid Search with Cross-Validation\n",
    "    grid_search = GridSearchCV(clf, mp['params'], cv=5, scoring='f1', n_jobs=-1)\n",
    "    grid_search.fit(X_resampled, y_resampled)\n",
    "    \n",
    "    # Get the best model from grid search\n",
    "    best_model = grid_search.best_estimator_\n",
    "    print(\"--------------- Best Model: ------------------\")\n",
    "    print(best_model)\n",
    "    \n",
    "    # Predictions on the test set\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    \n",
    "    # Print evaluation metrics\n",
    "    print(f\"Best parameters found: {grid_search.best_params_}\")\n",
    "    print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "    print(f\"Precision: {precision_score(y_test, y_pred):.4f}\")\n",
    "    print(f\"Recall: {recall_score(y_test, y_pred):.4f}\")\n",
    "    print(f\"F1 Score: {f1_score(y_test, y_pred):.4f}\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3437df6a-ce87-48f6-9ddd-15eefcdd2ffb",
   "metadata": {},
   "source": [
    "### Experiment Insights and Key Takeaways\n",
    "\n",
    "In this experiment, we evaluated four models: Decision Tree, Logistic Regression, LightGBM, and Random Forest. The goal was to determine the best-performing model based on accuracy, precision, recall, and F1 score, while also considering model explainability and robustness.\n",
    "\n",
    "#### 1. **Decision Tree:**\n",
    "- **Best Parameters**: `{'classifier__max_depth': None, 'classifier__min_samples_split': 2}`\n",
    "- **Performance**: \n",
    "  - **Accuracy**: 59.33%\n",
    "  - **Precision**: 32.87%\n",
    "  - **Recall**: 31.78%\n",
    "  - **F1 Score**: 32.32%\n",
    "  \n",
    "Decision Tree provided a relatively low performance compared to the other models. Its accuracy and F1 score are below 60%, and it showed limited capability in predicting the minority class (history of mental illness), with a recall of just ~31%. This indicates that the model is struggling to generalize well, especially given the class imbalance, even with SMOTE applied.\n",
    "\n",
    "#### 2. **Logistic Regression:**\n",
    "- **Best Parameters**: `{'classifier__C': 0.01, 'classifier__max_iter': 100, 'classifier__penalty': 'l2', 'classifier__solver': 'liblinear'}`\n",
    "- **Performance**: \n",
    "  - **Accuracy**: 61.72%\n",
    "  - **Precision**: 39.19%\n",
    "  - **Recall**: 45.86%\n",
    "  - **F1 Score**: 42.26%\n",
    "  \n",
    "Logistic Regression emerged as one of the best-performing models in this experiment. It achieved a good balance between precision and recall, with an F1 score of ~42%. Its simplicity and interpretability make it a strong candidate for the final model. Despite its slightly lower accuracy compared to other models, its performance in terms of recall (ability to identify positive cases of mental illness) is notable, making it a reliable choice for this problem.\n",
    "\n",
    "#### 3. **LightGBM:**\n",
    "- **Best Parameters**: `{'classifier__learning_rate': 0.05, 'classifier__max_depth': 30, 'classifier__n_estimators': 50}`\n",
    "- **Performance**: \n",
    "  - **Accuracy**: 63.92%\n",
    "  - **Precision**: 40.00%\n",
    "  - **Recall**: 36.21%\n",
    "  - **F1 Score**: 38.01%\n",
    "  \n",
    "LightGBM achieved the highest accuracy (63.92%) among the models, but its recall for the minority class was lower than Logistic Regression. While LightGBM offers powerful predictive performance, it tends to be less interpretable compared to simpler models like Logistic Regression. This makes it less desirable for this task, where model explainability is important.\n",
    "\n",
    "#### 4. **Random Forest:**\n",
    "- **Best Parameters**: `{'classifier__max_depth': 30, 'classifier__min_samples_split': 5, 'classifier__n_estimators': 150}`\n",
    "- **Performance**: \n",
    "  - **Accuracy**: 60.61%\n",
    "  - **Precision**: 34.03%\n",
    "  - **Recall**: 30.82%\n",
    "  - **F1 Score**: 32.34%\n",
    "  \n",
    "Random Forest provided moderate performance, similar to the Decision Tree model. Despite its slightly higher precision, the recall for the minority class remained relatively low (30.82%), which limits its effectiveness for identifying individuals with a history of mental illness. Its F1 score (32%) also indicates that it struggles to balance precision and recall effectively for this problem.\n",
    "\n",
    "### Final Model Choice: Logistic Regression\n",
    "\n",
    "Based on the performance of the models, **Logistic Regression** is the best model for our problem. Here are the key reasons for this choice:\n",
    "- **Balanced Performance**: Logistic Regression provided the best balance between precision and recall, resulting in an F1 score of ~42%. This balance is crucial for the task, where both false positives and false negatives can have significant implications.\n",
    "- **Explainability**: Logistic Regression is highly interpretable, allowing us to understand how each feature contributes to the predictions. This is important in real-world applications, especially in health-related domains, where decision-making transparency is essential.\n",
    "- **Simplicity**: Logistic Regression is computationally efficient and straightforward, making it easier to deploy and scale. While models like LightGBM and Random Forest offer marginally higher accuracy, they are more complex and less interpretable.\n",
    "- **Consistent Results**: Across both experiments (previous and current), Logistic Regression consistently performed well, especially when paired with SMOTE for addressing the class imbalance.\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "For our final model, we will proceed with **Logistic Regression**, using the best parameters found in this experiment (`C = 0.01, max_iter = 100, penalty = 'l2', solver = 'liblinear'`). This model offers the best combination of performance, simplicity, and explainability for predicting whether an individual is likely to suffer from mental illness.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe23e94c-6c2e-43b1-afed-8d251608cd0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
